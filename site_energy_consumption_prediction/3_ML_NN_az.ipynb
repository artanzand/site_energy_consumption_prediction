{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# from catboost import CatBoostRegressor\n",
    "# from lightgbm.sklearn import LGBMRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define scoring metrics and CV score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = {\n",
    "    \"neg RMSE\": \"neg_root_mean_squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "X_test_submit = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75757"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Any manual feature engineering before column transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Retail', 'Warehouse', 'Educational', 'Warehouse_cold', 'Office',\n",
       "       'Flex_space', 'Commercial', 'Industrial', 'Public_Assembly',\n",
       "       'Hotel', 'Health_care', 'Services', 'Food_services', 'Residential',\n",
       "       'Public_safety'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facility_class = pd.read_csv(\"f_type.csv\")\n",
    "facility_class[\"facility_class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Factor</th>\n",
       "      <th>State_Factor</th>\n",
       "      <th>building_class</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>energy_star_rating</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>january_min_temp</th>\n",
       "      <th>january_avg_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>days_above_90F</th>\n",
       "      <th>days_above_100F</th>\n",
       "      <th>days_above_110F</th>\n",
       "      <th>direction_max_wind_speed</th>\n",
       "      <th>direction_peak_wind_speed</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>days_with_fog</th>\n",
       "      <th>site_eui</th>\n",
       "      <th>id</th>\n",
       "      <th>facility_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>61242.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.682615</td>\n",
       "      <td>0</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>67346.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>287.863448</td>\n",
       "      <td>24</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>124196.0</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>241.932986</td>\n",
       "      <td>25</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Factor State_Factor building_class                 facility_type  \\\n",
       "0            1      State_1     Commercial  Grocery_store_or_food_market   \n",
       "1            1      State_1     Commercial  Grocery_store_or_food_market   \n",
       "2            1      State_1     Commercial  Grocery_store_or_food_market   \n",
       "\n",
       "   floor_area  year_built  energy_star_rating  ELEVATION  january_min_temp  \\\n",
       "0     61242.0      1942.0                11.0        2.4                36   \n",
       "1     67346.0      1967.0                26.0        1.8                36   \n",
       "2    124196.0      1954.0                44.0        1.8                36   \n",
       "\n",
       "   january_avg_temp  ...  days_above_90F  days_above_100F  days_above_110F  \\\n",
       "0              50.5  ...               0                0                0   \n",
       "1              50.5  ...               0                0                0   \n",
       "2              50.5  ...               0                0                0   \n",
       "\n",
       "   direction_max_wind_speed  direction_peak_wind_speed  max_wind_speed  \\\n",
       "0                       1.0                        1.0             1.0   \n",
       "1                       1.0                        NaN             1.0   \n",
       "2                       1.0                        NaN             1.0   \n",
       "\n",
       "   days_with_fog    site_eui  id  facility_class  \n",
       "0            NaN  248.682615   0          Retail  \n",
       "1           12.0  287.863448  24          Retail  \n",
       "2           12.0  241.932986  25          Retail  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, facility_class, on=\"facility_type\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75757, 65)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = df[\"direction_max_wind_speed\"]\n",
    "df['dir_max_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                np.where(value > 292.5, \"NE\",\n",
    "                                        np.where(value > 247.5, \"E\",\n",
    "                                                 np.where(value > 202.5, \"SE\",\n",
    "                                                          np.where(value > 157.5, \"S\",\n",
    "                                                                   np.where(value > 112.5, \"SW\",\n",
    "                                                                            np.where(value > 67.5, \"W\",\n",
    "                                                                                     np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "value = df[\"direction_peak_wind_speed\"]\n",
    "df['dir_peak_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                np.where(value > 292.5, \"NE\",\n",
    "                                        np.where(value > 247.5, \"E\",\n",
    "                                                 np.where(value > 202.5, \"SE\",\n",
    "                                                          np.where(value > 157.5, \"S\",\n",
    "                                                                   np.where(value > 112.5, \"SW\",\n",
    "                                                                            np.where(value > 67.5, \"W\",\n",
    "                                                                                     np.where(value > 22.5, \"NW\", \"N\"))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75757, 67)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'E', 'NE'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dir_max_wind_speed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'NE', 'E'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dir_peak_wind_speed'].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "value_floor = df[\"floor_area\"]\n",
    "df['ord_floor_area'] =  np.where(value_floor > 261980, 7,\n",
    "                              np.where(value_floor > 148466, 6,\n",
    "                                     np.where(value_floor > 105070, 5,\n",
    "                                            np.where(value_floor > 80088, 4,\n",
    "                                                  np.where(value_floor > 65333, 3,\n",
    "                                                         np.where(value_floor > 53250, 2, 1))))))\n",
    "\n",
    "df.groupby(['ord_floor_area']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the data I realized that the mean wind direction is 62 degrees which aligns with NE that we are getting above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following merges the imputed energy_star_rating\n",
    "# This was done in R\n",
    "df.to_csv(\"../data/train_facility.csv\") ## export for R MICE imputation\n",
    "energy_star_imp = pd.read_csv(\"energy_star_imp.csv\")\n",
    "df = pd.merge(df, energy_star_imp, on=\"facility_class\")\n",
    "df['energy_star_rating'] = df['energy_star_rating'].fillna(df.pop('energy_star_rating_imp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group columns for transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"site_eui\"\n",
    "\n",
    "numeric_features = [\n",
    "    \"floor_area\", # Grouped and moved to ordinary feature\n",
    "    \"year_built\",\n",
    "    \"energy_star_rating\", # Imputed by facility_class + site_eui, take the average per facility_class\n",
    "    # \"ELEVATION\", \n",
    "    \"january_min_temp\",\n",
    "    \"january_avg_temp\",\n",
    "    \"january_max_temp\",\n",
    "#    \"february_min_temp\", # removed similar temperature columns\n",
    "#    \"february_avg_temp\",\n",
    "#    \"february_max_temp\",\n",
    "#    \"march_min_temp\",\n",
    "#    \"march_avg_temp\",\n",
    "#    \"march_max_temp\",\n",
    "#    \"april_min_temp\",\n",
    "#    \"april_avg_temp\",\n",
    "#    \"april_max_temp\",\n",
    "#    \"may_min_temp\",\n",
    "#    \"may_avg_temp\",\n",
    "#    \"may_max_temp\",\n",
    "#    \"june_min_temp\",\n",
    "#    \"june_avg_temp\",\n",
    "#    \"june_max_temp\",\n",
    "    \"july_min_temp\",\n",
    "    \"july_avg_temp\",\n",
    "    \"july_max_temp\",\n",
    "    \"august_min_temp\",\n",
    "    \"august_avg_temp\",\n",
    "    \"august_max_temp\",\n",
    "#    \"september_min_temp\", # removed similar temperature columns\n",
    "#    \"september_avg_temp\",\n",
    "#    \"september_max_temp\",\n",
    "#    \"october_min_temp\",\n",
    "#    \"october_avg_temp\",\n",
    "#    \"october_max_temp\",\n",
    "#    \"november_min_temp\",\n",
    "#    \"november_avg_temp\",\n",
    "#    \"november_max_temp\",\n",
    "#    \"december_min_temp\",\n",
    "#    \"december_avg_temp\",\n",
    "#    \"december_max_temp\",\n",
    "    \"cooling_degree_days\",\n",
    "    \"heating_degree_days\",\n",
    "    \"precipitation_inches\",\n",
    "    \"snowfall_inches\",\n",
    "    \"snowdepth_inches\",\n",
    "    \"avg_temp\",\n",
    "   # \"days_below_30F\",\n",
    "    \"days_below_20F\",\n",
    "   # \"days_below_10F\", \n",
    "   # \"days_below_0F\",\n",
    "   # \"days_above_80F\",\n",
    "    \"days_above_90F\",\n",
    "   # \"days_above_100F\",\n",
    "   # \"days_above_110F\",\n",
    "   # \"direction_max_wind_speed\",\n",
    "   # \"direction_peak_wind_speed\",\n",
    "    \"max_wind_speed\",\n",
    "    \"days_with_fog\" ##???\n",
    "]\n",
    "\n",
    "ordinal_features = [] #['ord_floor_area']\n",
    "categorical_features = [\n",
    "                        \"Year_Factor\",  # Moved this down from numeric \n",
    "                        \"State_Factor\",\n",
    "                        \"facility_class\",\n",
    "                        \"facility_type\",\n",
    "                        \"dir_max_wind_speed\",  # Added new feature\n",
    "                        \"dir_peak_wind_speed\"]  # Added\n",
    "\n",
    "drop_features = [\n",
    "    \"id\",\n",
    "    \"building_class\", # Moved this one here \n",
    "    #\"floor_area\", # Grouped and moved this one here \n",
    "    \"direction_max_wind_speed\",\n",
    "    \"direction_peak_wind_speed\",\n",
    "    \"february_min_temp\",\n",
    "    \"february_avg_temp\",\n",
    "    \"february_max_temp\",\n",
    "    \"march_min_temp\",\n",
    "    \"march_avg_temp\",\n",
    "    \"march_max_temp\",\n",
    "    \"april_min_temp\",\n",
    "    \"april_avg_temp\",\n",
    "    \"april_max_temp\",\n",
    "    \"may_min_temp\",\n",
    "    \"may_avg_temp\",\n",
    "    \"may_max_temp\",\n",
    "    \"june_min_temp\",\n",
    "    \"june_avg_temp\",\n",
    "    \"june_max_temp\",    \n",
    "    \"september_min_temp\",\n",
    "    \"september_avg_temp\",\n",
    "    \"september_max_temp\",    \n",
    "    \"october_min_temp\",\n",
    "    \"october_avg_temp\",\n",
    "    \"october_max_temp\",\n",
    "    \"november_min_temp\",\n",
    "    \"november_avg_temp\",\n",
    "    \"november_max_temp\",\n",
    "    \"december_min_temp\",\n",
    "    \"december_avg_temp\",\n",
    "    \"december_max_temp\",    \n",
    "    \"days_below_30F\",    \n",
    "    \"days_below_10F\",\n",
    "    \"days_below_0F\",\n",
    "    \"days_above_80F\",    \n",
    "    \"days_above_100F\",\n",
    "    \"days_above_110F\",    \n",
    "    \"ELEVATION\", #Try dropping\n",
    "]\n",
    "\n",
    "assert df.columns.shape[0] == len(\n",
    "    numeric_features\n",
    "    + ordinal_features\n",
    "    + categorical_features\n",
    "    + [target]\n",
    "    + drop_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_test, y_test = test_df.drop(columns=[target]), test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column transformation & preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=0), StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check transformed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>floor_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>energy_star_rating</th>\n",
       "      <th>january_min_temp</th>\n",
       "      <th>january_avg_temp</th>\n",
       "      <th>january_max_temp</th>\n",
       "      <th>july_min_temp</th>\n",
       "      <th>july_avg_temp</th>\n",
       "      <th>july_max_temp</th>\n",
       "      <th>august_min_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>facility_type_Warehouse_Nonrefrigerated</th>\n",
       "      <th>facility_type_Warehouse_Refrigerated</th>\n",
       "      <th>facility_type_Warehouse_Selfstorage</th>\n",
       "      <th>facility_type_Warehouse_Uncategorized</th>\n",
       "      <th>dir_max_wind_speed_E</th>\n",
       "      <th>dir_max_wind_speed_N</th>\n",
       "      <th>dir_max_wind_speed_NE</th>\n",
       "      <th>dir_peak_wind_speed_E</th>\n",
       "      <th>dir_peak_wind_speed_N</th>\n",
       "      <th>dir_peak_wind_speed_NE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21568</th>\n",
       "      <td>-0.363151</td>\n",
       "      <td>0.284266</td>\n",
       "      <td>-0.071249</td>\n",
       "      <td>-0.045100</td>\n",
       "      <td>0.021364</td>\n",
       "      <td>-0.008784</td>\n",
       "      <td>0.582177</td>\n",
       "      <td>0.509584</td>\n",
       "      <td>0.111418</td>\n",
       "      <td>0.560097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72973</th>\n",
       "      <td>0.137007</td>\n",
       "      <td>0.165142</td>\n",
       "      <td>-1.836260</td>\n",
       "      <td>-0.045100</td>\n",
       "      <td>0.021364</td>\n",
       "      <td>-0.008784</td>\n",
       "      <td>0.582177</td>\n",
       "      <td>0.509584</td>\n",
       "      <td>0.111418</td>\n",
       "      <td>0.560097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8015</th>\n",
       "      <td>-0.245682</td>\n",
       "      <td>-0.016854</td>\n",
       "      <td>0.083425</td>\n",
       "      <td>-0.045100</td>\n",
       "      <td>0.021364</td>\n",
       "      <td>-0.008784</td>\n",
       "      <td>0.582177</td>\n",
       "      <td>0.509584</td>\n",
       "      <td>0.111418</td>\n",
       "      <td>0.560097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15042</th>\n",
       "      <td>-0.441739</td>\n",
       "      <td>0.261103</td>\n",
       "      <td>-2.051506</td>\n",
       "      <td>-2.068464</td>\n",
       "      <td>-1.766486</td>\n",
       "      <td>-2.434134</td>\n",
       "      <td>-2.289493</td>\n",
       "      <td>-1.445458</td>\n",
       "      <td>-0.369150</td>\n",
       "      <td>-1.911152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12129</th>\n",
       "      <td>-0.577481</td>\n",
       "      <td>0.274339</td>\n",
       "      <td>0.187045</td>\n",
       "      <td>3.149685</td>\n",
       "      <td>2.970395</td>\n",
       "      <td>2.603133</td>\n",
       "      <td>-1.810881</td>\n",
       "      <td>-2.367796</td>\n",
       "      <td>-1.330285</td>\n",
       "      <td>-0.338539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       floor_area  year_built  energy_star_rating  january_min_temp  \\\n",
       "21568   -0.363151    0.284266           -0.071249         -0.045100   \n",
       "72973    0.137007    0.165142           -1.836260         -0.045100   \n",
       "8015    -0.245682   -0.016854            0.083425         -0.045100   \n",
       "15042   -0.441739    0.261103           -2.051506         -2.068464   \n",
       "12129   -0.577481    0.274339            0.187045          3.149685   \n",
       "\n",
       "       january_avg_temp  january_max_temp  july_min_temp  july_avg_temp  \\\n",
       "21568          0.021364         -0.008784       0.582177       0.509584   \n",
       "72973          0.021364         -0.008784       0.582177       0.509584   \n",
       "8015           0.021364         -0.008784       0.582177       0.509584   \n",
       "15042         -1.766486         -2.434134      -2.289493      -1.445458   \n",
       "12129          2.970395          2.603133      -1.810881      -2.367796   \n",
       "\n",
       "       july_max_temp  august_min_temp  ...  \\\n",
       "21568       0.111418         0.560097  ...   \n",
       "72973       0.111418         0.560097  ...   \n",
       "8015        0.111418         0.560097  ...   \n",
       "15042      -0.369150        -1.911152  ...   \n",
       "12129      -1.330285        -0.338539  ...   \n",
       "\n",
       "       facility_type_Warehouse_Nonrefrigerated  \\\n",
       "21568                                      0.0   \n",
       "72973                                      0.0   \n",
       "8015                                       0.0   \n",
       "15042                                      0.0   \n",
       "12129                                      0.0   \n",
       "\n",
       "       facility_type_Warehouse_Refrigerated  \\\n",
       "21568                                   0.0   \n",
       "72973                                   0.0   \n",
       "8015                                    0.0   \n",
       "15042                                   0.0   \n",
       "12129                                   0.0   \n",
       "\n",
       "       facility_type_Warehouse_Selfstorage  \\\n",
       "21568                                  0.0   \n",
       "72973                                  0.0   \n",
       "8015                                   0.0   \n",
       "15042                                  0.0   \n",
       "12129                                  0.0   \n",
       "\n",
       "       facility_type_Warehouse_Uncategorized  dir_max_wind_speed_E  \\\n",
       "21568                                    0.0                   0.0   \n",
       "72973                                    0.0                   0.0   \n",
       "8015                                     0.0                   0.0   \n",
       "15042                                    0.0                   0.0   \n",
       "12129                                    0.0                   0.0   \n",
       "\n",
       "       dir_max_wind_speed_N  dir_max_wind_speed_NE  dir_peak_wind_speed_E  \\\n",
       "21568                   1.0                    0.0                    0.0   \n",
       "72973                   1.0                    0.0                    0.0   \n",
       "8015                    1.0                    0.0                    0.0   \n",
       "15042                   1.0                    0.0                    0.0   \n",
       "12129                   1.0                    0.0                    0.0   \n",
       "\n",
       "       dir_peak_wind_speed_N  dir_peak_wind_speed_NE  \n",
       "21568                    1.0                     0.0  \n",
       "72973                    1.0                     0.0  \n",
       "8015                     1.0                     0.0  \n",
       "15042                    1.0                     0.0  \n",
       "12129                    1.0                     0.0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = (\n",
    "    numeric_features\n",
    "    + preprocessor.named_transformers_[\"pipeline-2\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "X_train_transformed_df = pd.DataFrame(\n",
    "    X_train_transformed.toarray(), columns=column_names, index=X_train.index\n",
    ")\n",
    "\n",
    "X_train_transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dummy regressor as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# pipe_dummy = DummyRegressor()\n",
    "# results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "#     pipe_dummy, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "# )\n",
    "# pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train several models (CV) and retrieve the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipe_ridge = make_pipeline(preprocessor, Ridge(random_state=123))\n",
    "\n",
    "# pipe_rf = make_pipeline(\n",
    "#     preprocessor, RandomForestRegressor(random_state=123, n_jobs=-1, max_depth=5)\n",
    "# )\n",
    "\n",
    "# pipe_xgb = make_pipeline(\n",
    "#     preprocessor, XGBRegressor(random_state=123, n_jobs=-1, verbosity=0)\n",
    "# )\n",
    "\n",
    "# pipe_lgbm = make_pipeline(preprocessor, LGBMRegressor(random_state=123))\n",
    "\n",
    "# pipe_catboost = make_pipeline(\n",
    "#     preprocessor, CatBoostRegressor(random_state=123, verbose=0)\n",
    "# )\n",
    "\n",
    "# models = {\n",
    "#     #\"Ridge\": pipe_ridge, ## high mse\n",
    "#     #\"Random Forest\": pipe_rf,\n",
    "#     \"XGBoost\": pipe_xgb,\n",
    "#     \"LightGBM\": pipe_lgbm,\n",
    "#     \"CatBoost\": pipe_catboost,\n",
    "#     #\"kNN\": pipe_kNN,  ## high mse\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for model_name, model in models.items():\n",
    "#     results[model_name] = mean_std_cross_val_scores(\n",
    "#         model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "param_grid_xgb = {\n",
    "     \"xgbregressor__max_depth\": np.linspace(start=1, stop=20, num=5, dtype=int),\n",
    "     \"xgbregressor__min_child_weight\": np.linspace(start=1, stop=20, num=5, dtype=int),\n",
    "     \"xgbregressor__subsample\": np.logspace(-3, 0, 10),\n",
    "     \"xgbregressor__colsample_bytree\": np.logspace(-3, 0, 10),\n",
    "     \"xgbregressor__eta\": np.logspace(-3, 0, 10)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "xgb_search_rf = RandomizedSearchCV(\n",
    "    pipe_xgb,\n",
    "    param_grid_xgb,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    random_state=123,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "xgb_search_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "train =  h2o.H2OFrame(df)\n",
    "aml = H2OAutoML(max_runtime_secs=2000, seed=1)\n",
    "aml.train(x=numeric_features + ordinal_features + categorical_features, y=target, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# averaging_model = VotingRegressor(\n",
    "#     list(models.items())\n",
    "# )  # need the list() here for cross-validation to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# averaging_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results[\"Voting\"] = mean_std_cross_val_scores(\n",
    "#     averaging_model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stacking_model = StackingRegressor(\n",
    "#     list(models.items())\n",
    "# )  # need the list() here for cross-validation to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stacking_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results[\"Stacking\"] = mean_std_cross_val_scores(\n",
    "#     stacking_model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = averaging_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_fitted = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_score = pipe.score(X_test, y_test)\n",
    "# final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# AutoML prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test =  h2o.H2OFrame(X_test_submit)\n",
    "preds = aml.predict(test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "submission2 = pd.DataFrame({'id': X_test_submit[\"id\"], 'site_eui': h2o.as_list(preds)['predict']})\n",
    "submission2.head()\n",
    "submission2.to_csv(\"test3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([68181, 116])\n",
      "torch.Size([68181])\n"
     ]
    }
   ],
   "source": [
    "# transform validation set\n",
    "X_valid_transformed = preprocessor.transform(X_test)\n",
    "X_valid_transformed_df = pd.DataFrame(\n",
    "    X_valid_transformed.toarray(), columns=column_names, index=X_test.index\n",
    ")\n",
    "\n",
    "X_valid_t = torch.tensor(X_valid_transformed_df.to_numpy(np.float32), dtype=torch.float32)\n",
    "y_valid_t = torch.tensor(y_test.to_numpy(np.float32), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# transform train set to tensor\n",
    "X_t = torch.tensor(X_train_transformed_df.to_numpy(np.float32), dtype=torch.float32)\n",
    "y_t = torch.tensor(y_train.to_numpy(np.float32), dtype=torch.float32)\n",
    "\n",
    "print(X_t.shape)\n",
    "print(y_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataset = TensorDataset(X_t, y_t)\n",
    "valid_dataset = TensorDataset(X_valid_t, y_valid_t)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train class\n",
    "def trainer(model, device, criterion, optimizer, trainloader, validloader, epochs=5, verbose=True):\n",
    "    \"\"\"Simple training wrapper for PyTorch network.\"\"\"\n",
    "    \n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    train_accuracy = []\n",
    "    valid_accuracy = []\n",
    "    \n",
    "    for epoch in range(epochs):  # for each epoch\n",
    "        \n",
    "        train_batch_loss = 0\n",
    "        train_batch_acc = 0\n",
    "        valid_batch_loss = 0\n",
    "        valid_batch_acc = 0\n",
    "        \n",
    "        # Training\n",
    "        for X, y in trainloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()       # Zero all the gradients w.r.t. parameters\n",
    "            y_hat = model(X).flatten()\n",
    "            loss = criterion(y_hat, y)   # Calculate loss based on output\n",
    "            loss.backward()             # Calculate gradients w.r.t. parameters\n",
    "            optimizer.step()            # Update parameters\n",
    "            train_batch_loss += loss.item()  # Add loss for this batch to running total\n",
    "            train_batch_acc += (torch.sqrt(torch.mean((y_hat-y)**2))*-1).type(torch.float32).item()   \n",
    "            \n",
    "        train_loss.append(train_batch_loss / len(trainloader))     # loss = total loss in epoch / number of batches = loss per batch\n",
    "        train_accuracy.append(train_batch_acc / len(trainloader))  # accuracy\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()  # this turns off those random dropout layers, we don't want them for validation!\n",
    "        \n",
    "        with torch.no_grad():  # this stops pytorch doing computational graph stuff under-the-hood and saves memory and time\n",
    "            for X, y in validloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X).flatten()  # Forward pass to get output\n",
    "                loss = criterion(y_hat, y)   # Calculate loss based on output\n",
    "                valid_batch_loss += loss.item()                  # Add loss for this batch to running total\n",
    "                valid_batch_acc += (torch.sqrt(torch.mean((y_hat-y)**2))*-1).type(torch.float32).item()   # Average accuracy for this batch\n",
    "                \n",
    "        valid_loss.append(valid_batch_loss / len(validloader))\n",
    "        valid_accuracy.append(valid_batch_acc / len(validloader))  # accuracy in terms of RMSE\n",
    "        \n",
    "        model.train()  # turn back on the dropout layers for the next training loop\n",
    "        \n",
    "        # Print progress\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch + 1:3}:\",\n",
    "                  f\"Train Loss: {train_loss[-1]:.3f}.\",\n",
    "                  f\"Valid Loss: {valid_loss[-1]:.3f}.\",\n",
    "                  f\"Train Accuracy: {train_accuracy[-1]:.2f}.\",\n",
    "                  f\"Valid Accuracy: {valid_accuracy[-1]:.2f}.\")\n",
    "    \n",
    "    results = {\"train_loss\": train_loss,\n",
    "               \"valid_loss\": valid_loss,\n",
    "               \"train_accuracy\": train_accuracy,\n",
    "               \"valid_accuracy\": valid_accuracy}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NN Architecture\n",
    "class site_model(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(16, 8),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(8, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to device\n",
    "nn_model = site_model(X_t.shape[1])\n",
    "nn_model.to(device)\n",
    "\n",
    "# # Criterion and optimizer\n",
    "# def RMSE(y_hat, y):\n",
    "#     return torch.sqrt(torch.mean((y_hat - y) ** 2))\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train Loss: 80.166. Valid Loss: 75.990. Train Accuracy: -98.13. Valid Accuracy: -95.59.\n",
      "Epoch   2: Train Loss: 67.766. Valid Loss: 57.309. Train Accuracy: -87.89. Valid Accuracy: -79.99.\n",
      "Epoch   3: Train Loss: 45.327. Valid Loss: 33.448. Train Accuracy: -69.24. Valid Accuracy: -60.16.\n",
      "Epoch   4: Train Loss: 30.781. Valid Loss: 25.319. Train Accuracy: -55.04. Valid Accuracy: -50.33.\n",
      "Epoch   5: Train Loss: 27.852. Valid Loss: 23.727. Train Accuracy: -49.72. Valid Accuracy: -47.67.\n",
      "Epoch   6: Train Loss: 27.276. Valid Loss: 22.943. Train Accuracy: -48.74. Valid Accuracy: -45.96.\n",
      "Epoch   7: Train Loss: 27.130. Valid Loss: 22.806. Train Accuracy: -48.27. Valid Accuracy: -46.09.\n",
      "Epoch   8: Train Loss: 26.870. Valid Loss: 22.961. Train Accuracy: -47.86. Valid Accuracy: -46.41.\n",
      "Epoch   9: Train Loss: 26.745. Valid Loss: 22.544. Train Accuracy: -47.64. Valid Accuracy: -45.32.\n",
      "Epoch  10: Train Loss: 26.633. Valid Loss: 22.961. Train Accuracy: -47.45. Valid Accuracy: -45.47.\n"
     ]
    }
   ],
   "source": [
    "training = trainer(nn_model, device, criterion, optimizer, train_loader, valid_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.array(training['train_loss']), label='train_loss')\n",
    "plt.plot(np.array(training['valid_loss']), label='valid_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(training['train_accuracy']), label='train')\n",
    "plt.plot(np.array(training['valid_accuracy']), label='valid')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_submit['facility_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of test set\n",
    "X_test_submit = pd.merge(X_test_submit, facility_class, on=\"facility_type\")\n",
    "\n",
    "# Impute energy_star_rating\n",
    "X_test_submit = pd.merge(X_test_submit, energy_star_imp, on=\"facility_class\")\n",
    "X_test_submit['energy_star_rating'] = X_test_submit['energy_star_rating'].fillna(X_test_submit.pop('energy_star_rating_imp'))\n",
    "\n",
    "\n",
    "value = X_test_submit[\"direction_max_wind_speed\"]\n",
    "X_test_submit['dir_max_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                            np.where(value > 292.5, \"NE\",\n",
    "                                                    np.where(value > 247.5, \"E\",\n",
    "                                                             np.where(value > 202.5, \"SE\",\n",
    "                                                                      np.where(value > 157.5, \"S\",\n",
    "                                                                               np.where(value > 112.5, \"SW\",\n",
    "                                                                                        np.where(value > 67.5, \"W\",\n",
    "                                                                                                 np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "value = X_test_submit[\"direction_peak_wind_speed\"]\n",
    "X_test_submit['dir_peak_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                            np.where(value > 292.5, \"NE\",\n",
    "                                                    np.where(value > 247.5, \"E\",\n",
    "                                                             np.where(value > 202.5, \"SE\",\n",
    "                                                                      np.where(value > 157.5, \"S\",\n",
    "                                                                               np.where(value > 112.5, \"SW\",\n",
    "                                                                                        np.where(value > 67.5, \"W\",\n",
    "                                                                                                 np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "#value_floor = X_test_submit[\"floor_area\"]\n",
    "#X_test_submit['ord_floor_area'] =  np.where(value_floor > 261980, 7,\n",
    "#                              np.where(value_floor > 148466, 6,\n",
    "#                                     np.where(value_floor > 105070, 5,\n",
    "#                                            np.where(value_floor > 80088, 4,\n",
    "#                                                  np.where(value_floor > 65333, 3,\n",
    "#                                                         np.where(value_floor > 53250, 2, 1))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select your submission model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = preprocessor.transform(X_test_submit).toarray()\n",
    "column_names_testing = (\n",
    "    numeric_features\n",
    "    + preprocessor.named_transformers_[\"pipeline-2\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    "    .tolist()\n",
    ")\n",
    "X_test_transformed = pd.DataFrame(\n",
    "   X_test_transformed, columns=column_names_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State factor 6 needs to be manually added in\n",
    "X_test_transformed['State_Factor_State_6'] = 0\n",
    "\n",
    "# reorder columns to be in same order as training set\n",
    "X_test_transformed = X_test_transformed[X_train_transformed_df.columns]\n",
    "\n",
    "# Change to tensor\n",
    "X_test_transformed= torch.tensor(X_test_transformed.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = []\n",
    "# for i in range(0,X_test_transformed.shape[0]):\n",
    "#     prediction.append( model(X_test_transformed[i]).item())\n",
    "\n",
    "prediction = nn_model(X_test_transformed).detach().numpy().flatten()\n",
    "  \n",
    "submission = pd.DataFrame({'id': X_test_submit['id'], 'site_eui': prediction})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsci572env]",
   "language": "python",
   "name": "conda-env-dsci572env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
