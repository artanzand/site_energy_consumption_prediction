{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "import torch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define scoring metrics and CV score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = {\n",
    "    \"neg RMSE\": \"neg_root_mean_squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == \"cuda\":\n",
    "    df = pd.read_csv('../input/mds-snowbies/train.csv')\n",
    "    X_test_submit = pd.read_csv('../input/mds-snowbies/test.csv')\n",
    "else:\n",
    "    df = pd.read_csv('../data/train.csv')\n",
    "    X_test_submit = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Any manual feature engineering before column transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == \"cuda\":\n",
    "    facility_class = pd.read_csv(\"../input/mds-snowbies/f_type.csv\")\n",
    "else:\n",
    "    facility_class = pd.read_csv(\"f_type.csv\")\n",
    "    \n",
    "facility_class[\"facility_class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, facility_class, on=\"facility_type\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = df[\"direction_max_wind_speed\"]\n",
    "df['dir_max_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                np.where(value > 292.5, \"NE\",\n",
    "                                        np.where(value > 247.5, \"E\",\n",
    "                                                 np.where(value > 202.5, \"SE\",\n",
    "                                                          np.where(value > 157.5, \"S\",\n",
    "                                                                   np.where(value > 112.5, \"SW\",\n",
    "                                                                            np.where(value > 67.5, \"W\",\n",
    "                                                                                     np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "value = df[\"direction_peak_wind_speed\"]\n",
    "df['dir_peak_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                np.where(value > 292.5, \"NE\",\n",
    "                                        np.where(value > 247.5, \"E\",\n",
    "                                                 np.where(value > 202.5, \"SE\",\n",
    "                                                          np.where(value > 157.5, \"S\",\n",
    "                                                                   np.where(value > 112.5, \"SW\",\n",
    "                                                                            np.where(value > 67.5, \"W\",\n",
    "                                                                                     np.where(value > 22.5, \"NW\", \"N\"))))))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df[\"february_avg_temp_diff\"] = df[\"february_avg_temp\"]   - df[\"january_avg_temp\"]\n",
    "df[\"march_avg_temp_diff\"] = df[\"march_avg_temp\"]   - df[\"february_avg_temp\"]\n",
    "df[\"april_avg_temp_diff\"] = df[\"april_avg_temp\"]   - df[\"march_avg_temp\"]\n",
    "df[\"may_avg_temp_diff\"] = df[\"may_avg_temp\"]   - df[\"april_avg_temp\"]\n",
    "df[\"june_avg_temp_diff\"] = df[\"june_avg_temp\"]   - df[\"may_avg_temp\"]\n",
    "df[\"july_avg_temp_diff\"] = df[\"july_avg_temp\"]   - df[\"june_avg_temp\"]\n",
    "df[\"august_avg_temp_diff\"] = df[\"august_avg_temp\"]   - df[\"july_avg_temp\"]\n",
    "df[\"september_avg_temp_diff\"] = df[\"september_avg_temp\"]   - df[\"august_avg_temp\"]\n",
    "df[\"october_avg_temp_diff\"] = df[\"october_avg_temp\"]   - df[\"september_avg_temp\"]\n",
    "df[\"november_avg_temp_diff\"] = df[\"november_avg_temp\"]   - df[\"october_avg_temp\"]\n",
    "df[\"december_avg_temp_diff\"] = df[\"december_avg_temp\"]   - df[\"november_avg_temp\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "value_floor = df[\"floor_area\"]\n",
    "df['ord_floor_area'] =  np.where(value_floor > 261980, 7,\n",
    "                              np.where(value_floor > 148466, 6,\n",
    "                                     np.where(value_floor > 105070, 5,\n",
    "                                            np.where(value_floor > 80088, 4,\n",
    "                                                  np.where(value_floor > 65333, 3,\n",
    "                                                         np.where(value_floor > 53250, 2, 1))))))\n",
    "\n",
    "df.groupby(['ord_floor_area']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the data I realized that the mean wind direction is 62 degrees which aligns with NE that we are getting above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ditch MICE use KNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The following merges the imputed energy_star_rating\n",
    "# This was done in R\n",
    "df.to_csv(\"../data/train_facility.csv\") ## export for R MICE imputation\n",
    "energy_star_imp = pd.read_csv(\"energy_star_imp.csv\")\n",
    "df = pd.merge(df, energy_star_imp, on=\"facility_class\")\n",
    "df['energy_star_rating'] = df['energy_star_rating'].fillna(df.pop('energy_star_rating_imp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group columns for transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"site_eui\"\n",
    "\n",
    "numeric_features = [\n",
    "    \"floor_area\",\n",
    "    \"Year_Factor\",\n",
    "    #    \"year_built\",\n",
    "    \"energy_star_rating\",  # Imputed by facility_class + site_eui, take the average per facility_class\n",
    "    #    \"ELEVATION\",\n",
    "    \"january_min_temp\",\n",
    "    \"january_avg_temp\",\n",
    "    \"january_max_temp\",\n",
    "    #    \"february_min_temp\", # removed similar temperature columns\n",
    "    #    \"february_avg_temp\",\n",
    "    #    \"february_max_temp\",\n",
    "    #    \"march_min_temp\",\n",
    "    #    \"march_avg_temp\",\n",
    "    #    \"march_max_temp\",\n",
    "    #    \"april_min_temp\",\n",
    "    #    \"april_avg_temp\",\n",
    "    #    \"april_max_temp\",\n",
    "    #    \"may_min_temp\",\n",
    "    #    \"may_avg_temp\",\n",
    "    #    \"may_max_temp\",\n",
    "    #    \"june_min_temp\",\n",
    "    #    \"june_avg_temp\",\n",
    "    #    \"june_max_temp\",\n",
    "    \"july_min_temp\",\n",
    "    \"july_avg_temp\",\n",
    "    \"july_max_temp\",\n",
    "    #    \"august_min_temp\",\n",
    "    #    \"august_avg_temp\",\n",
    "    #    \"august_max_temp\",\n",
    "    #    \"september_min_temp\", # removed similar temperature columns\n",
    "    #    \"september_avg_temp\",\n",
    "    #    \"september_max_temp\",\n",
    "    #    \"october_min_temp\",\n",
    "    #    \"october_avg_temp\",\n",
    "    #    \"october_max_temp\",\n",
    "    #    \"november_min_temp\",\n",
    "    #    \"november_avg_temp\",\n",
    "    #    \"november_max_temp\",\n",
    "    #    \"december_min_temp\",\n",
    "    #    \"december_avg_temp\",\n",
    "    #    \"december_max_temp\",\n",
    "    \"cooling_degree_days\",\n",
    "    \"heating_degree_days\",\n",
    "    \"precipitation_inches\",\n",
    "    \"snowfall_inches\",\n",
    "    \"snowdepth_inches\",\n",
    "    #    \"avg_temp\",\n",
    "    #    \"days_below_30F\",\n",
    "    \"days_below_20F\",\n",
    "    #    \"days_below_10F\",\n",
    "    #    \"days_below_0F\",\n",
    "    #    \"days_above_80F\",\n",
    "    \"days_above_90F\",\n",
    "    #    \"days_above_100F\",\n",
    "    #    \"days_above_110F\",\n",
    "    #    \"direction_max_wind_speed\",\n",
    "    #    \"direction_peak_wind_speed\",\n",
    "    #    \"max_wind_speed\",\n",
    "    #    \"days_with_fog\",\n",
    "    \"february_avg_temp_diff\",\n",
    "    \"march_avg_temp_diff\",\n",
    "    \"april_avg_temp_diff\",\n",
    "    \"may_avg_temp_diff\",\n",
    "    \"june_avg_temp_diff\",\n",
    "    \"july_avg_temp_diff\",\n",
    "    \"august_avg_temp_diff\",\n",
    "    \"september_avg_temp_diff\",\n",
    "    \"october_avg_temp_diff\",\n",
    "    \"november_avg_temp_diff\",\n",
    "    \"december_avg_temp_diff\"\n",
    "]\n",
    "\n",
    "year_features = [\"year_built\"]\n",
    "ordinal_features = [] \n",
    "categorical_features = [\n",
    "    \"State_Factor\",\n",
    "    \"facility_class\",\n",
    "    \"facility_type\",\n",
    "    \"dir_max_wind_speed\",  # Added new feature\n",
    "    \"dir_peak_wind_speed\",\n",
    "]  \n",
    "\n",
    "drop_features = [\n",
    "    \"id\",\n",
    "    \"building_class\",  # Moved this one here\n",
    "    \"ELEVATION\",    \n",
    "    \"direction_max_wind_speed\",\n",
    "    \"direction_peak_wind_speed\", \n",
    "    \"february_min_temp\",\n",
    "    \"february_avg_temp\",\n",
    "    \"february_max_temp\",\n",
    "    \"march_min_temp\",\n",
    "    \"march_avg_temp\",\n",
    "    \"march_max_temp\",\n",
    "    \"april_min_temp\",\n",
    "    \"april_avg_temp\",\n",
    "    \"april_max_temp\",\n",
    "    \"may_min_temp\",\n",
    "    \"may_avg_temp\",\n",
    "    \"may_max_temp\",\n",
    "    \"june_min_temp\",\n",
    "    \"june_avg_temp\",\n",
    "    \"june_max_temp\",     \n",
    "    \"august_min_temp\",\n",
    "    \"august_avg_temp\",\n",
    "    \"august_max_temp\",\n",
    "    \"september_min_temp\",\n",
    "    \"september_avg_temp\",\n",
    "    \"september_max_temp\",\n",
    "    \"october_min_temp\",\n",
    "    \"october_avg_temp\",\n",
    "    \"october_max_temp\",\n",
    "    \"november_min_temp\",\n",
    "    \"november_avg_temp\",\n",
    "    \"november_max_temp\",\n",
    "    \"december_min_temp\",\n",
    "    \"december_avg_temp\",\n",
    "    \"december_max_temp\",\n",
    "    \"avg_temp\",    \n",
    "    \"days_below_30F\",\n",
    "    \"days_below_10F\",\n",
    "    \"days_below_0F\",\n",
    "    \"days_above_80F\",\n",
    "    \"days_above_100F\",\n",
    "    \"days_above_110F\",\n",
    "    \"max_wind_speed\",\n",
    "    \"days_with_fog\"\n",
    "]\n",
    "\n",
    "assert df.columns.shape[0] == len(\n",
    "    numeric_features\n",
    "    + year_features\n",
    "    + ordinal_features\n",
    "    + categorical_features\n",
    "    + [target]\n",
    "    + drop_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_test, y_test = test_df.drop(columns=[target]), test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn Regression for energy star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_features = [\"floor_area\", \"year_built\", \"facility_type\"]\n",
    "\n",
    "train_df_energy_notna = X_train[X_train[\"energy_star_rating\"].notna()]\n",
    "X_energy, y_energy = train_df_energy_notna[knn_features], train_df_energy_notna[\"energy_star_rating\"]\n",
    "\n",
    "# for imputataion from knn prediction later\n",
    "train_df_energy_isna = X_train[X_train[\"energy_star_rating\"].isna()]\n",
    "test_df_energy_isna = X_test[X_test[\"energy_star_rating\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_transformer_energy = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=0), StandardScaler())\n",
    "numeric_transformer_energy = make_pipeline(KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean'), StandardScaler())\n",
    "year_transformer_energy = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=1930), StandardScaler())\n",
    "\n",
    "\n",
    "categorical_transformer_energy = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=True),\n",
    ")\n",
    "\n",
    "preprocessor_energy = make_column_transformer(\n",
    "    (numeric_transformer_energy, [\"floor_area\"]),\n",
    "    (year_transformer_energy, [\"year_built\"]),\n",
    "    (categorical_transformer_energy, [\"facility_type\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(1,10):\n",
    "\n",
    "#     pipe_knn_energy = make_pipeline(\n",
    "#         preprocessor_energy, KNeighborsRegressor(n_neighbors=i,n_jobs=-1)\n",
    "#     )\n",
    "\n",
    "#     results_energy[\"knn_\"+str(i)] = mean_std_cross_val_scores(\n",
    "#         pipe_knn_energy, X_train_energy, y_train_energy, return_train_score=True, scoring=scoring_metrics\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(results_energy).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run if requires retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn_energy = make_pipeline(\n",
    "        preprocessor_energy, KNeighborsRegressor(n_neighbors=3,n_jobs=-1, weights=\"distance\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn_fitted = pipe_knn_energy.fit(X_energy, y_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained KNN regression model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save pipe_knn_energy model\n",
    "try:\n",
    "    filename = \"pipe_knn_fitted.p\"\n",
    "    outfile = open(\"pipe_knn_fitted.p\", \"wb\")\n",
    "    pickle.dump(pipe_knn_fitted, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Pipe is dumped successfully\")\n",
    "\n",
    "except Exception as error:\n",
    "    print(f\"Error message: %s\" % error)\n",
    "    print(\"Error while saving pipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained KNN regression model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file = open('pipe_knn_fitted.p', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "pipe_knn_fitted = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_na = train_df_energy_isna[knn_features]\n",
    "#y_pred = pipe_knn_fitted.predict(X_train_df_na)\n",
    "y_pred = [100 if y > 100 else y for y in pipe_knn_fitted.predict(X_train_df_na)]\n",
    "y_pred_df = pd.DataFrame({\"energy_star_rating\": y_pred}, index = X_train_df_na.index)\n",
    "X_train.fillna(value = y_pred_df, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute X_test (our validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df_na = test_df_energy_isna[knn_features]\n",
    "y_pred = [100 if y > 100 else y for y in pipe_knn_fitted.predict(X_test_df_na)]\n",
    "y_pred_df = pd.DataFrame({\"energy_star_rating\": y_pred}, index = X_test_df_na.index)\n",
    "X_test.fillna(value = y_pred_df, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train[\"energy_star_rating\"].isna().sum() + X_test[\"energy_star_rating\"].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column transformation & preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_transformer = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=0), StandardScaler())\n",
    "numeric_transformer = make_pipeline(KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean'), StandardScaler())\n",
    "year_transformer = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=1930), StandardScaler())\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (year_transformer, year_features),        \n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check transformed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = (\n",
    "    numeric_features\n",
    "    + year_features    \n",
    "    + preprocessor.named_transformers_[\"pipeline-3\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "X_train_transformed_df = pd.DataFrame(\n",
    "    X_train_transformed.toarray(), columns=column_names, index=X_train.index\n",
    ")\n",
    "\n",
    "X_train_transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy regressor as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "pipe_dummy = DummyRegressor()\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    pipe_dummy, X_train, y_train, return_train_score=True, scoring='neg_mean_squared_error'\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_important = pipe[2].get_booster().get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "#data.nlargest(40, columns=\"score\").plot(kind='barh', figsize = (20,10)) ## plot top 40 features\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train several models (CV) and retrieve the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(preprocessor, Ridge(random_state=123))\n",
    "\n",
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestRegressor(n_estimators = 300, random_state=123, n_jobs=-1)\n",
    ")\n",
    "\n",
    "pipe_xgb = make_pipeline(\n",
    "    preprocessor, XGBRegressor(random_state=123, \n",
    "                               n_jobs=-1, \n",
    "                               verbosity=0, \n",
    "                               n_estimators=10000, #28000\n",
    "                               #tree_method='gpu_hist', \n",
    "                               #gpu_id=0\n",
    "                              )\n",
    ")\n",
    "\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMRegressor(#num_leaves = 32, \n",
    "                                                      #min_child_samples=100, \n",
    "                                                      random_state=123,\n",
    "                                                      #feature_fraction = 0.9,\n",
    "                                                      #lambda_l1 = 10, lambda_l2 = 10,\n",
    "                                                      #bagging_freq=1,\n",
    "                                                      #bagging_fraction=0.9,\n",
    "                                                      verbose = 0,\n",
    "                                                      n_estimators=10000, #28000\n",
    "                                                      #device='gpu',\n",
    "                                                      #force_col_wise=True,\n",
    "                                                      # boosting=\"dart\",\n",
    "                                                      drop_seed=123\n",
    "                                                     ))\n",
    "\n",
    "pipe_catboost = make_pipeline( preprocessor, CatBoostRegressor( verbose=0,\n",
    "                                                                early_stopping_rounds=10,\n",
    "                                                                random_seed=123,\n",
    "                                                                max_depth=12,\n",
    "                                                                learning_rate=0.025,\n",
    "                                                                loss_function='RMSE',\n",
    "                                                                eval_metric= 'RMSE',\n",
    "                                                                iterations=20000, #28000,\n",
    "                                                                # task_type='GPU',\n",
    "                                                                \n",
    "                                                            ))\n",
    "\n",
    "models = {\n",
    "    #\"Ridge\": pipe_ridge,\n",
    "    #\"Random Forest\": pipe_rf,\n",
    "    \"XGBoost\": pipe_xgb,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost,\n",
    "    #\"kNN\": pipe_kNN,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for model_name, model in models.items():\n",
    "    results[model_name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid_xgb = {\n",
    "     \"xgbregressor__max_depth\": np.linspace(start=1, stop=20, num=5, dtype=int),\n",
    "     \"xgbregressor__min_child_weight\": np.linspace(start=1, stop=20, num=5, dtype=int),\n",
    "     \"xgbregressor__subsample\": np.logspace(-3, 0, 10),\n",
    "     \"xgbregressor__colsample_bytree\": np.logspace(-3, 0, 10),\n",
    "     \"xgbregressor__eta\": np.logspace(-3, 0, 10)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xgb_search_rf = RandomizedSearchCV(\n",
    "    pipe_xgb,\n",
    "    param_grid_xgb,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    random_state=123,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "xgb_search_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "averaging_model = VotingRegressor(\n",
    "    list(models.items())\n",
    ")  # need the list() here for cross-validation to work!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "averaging_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results[\"Voting\"] = mean_std_cross_val_scores(\n",
    "    averaging_model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingRegressor(\n",
    "    list(models.items())\n",
    ")  # need the list() here for cross-validation to work!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stacking_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results[\"Stacking\"] = mean_std_cross_val_scores(\n",
    "    stacking_model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the selected model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = pipe_xgb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe_fitted = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred = pipe_fitted.predict(X_test)\n",
    "final_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "final_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = pipe_lgbm\n",
    "pipe_fitted = pipe.fit(X_train, y_train)\n",
    "y_pred = pipe_fitted.predict(X_test)\n",
    "final_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of test set\n",
    "X_test_submit = pd.merge(X_test_submit, facility_class, on=\"facility_type\")\n",
    "\n",
    "# Impute energy_star_rating by kNN\n",
    "X_test_submit_energy_isna = X_test_submit[X_test_submit[\"energy_star_rating\"].isna()]\n",
    "X_test_submit_na = X_test_submit_energy_isna[knn_features]\n",
    "y_pred = [100 if y > 100 else y for y in pipe_knn_fitted.predict(X_test_submit_na)]\n",
    "y_pred_df = pd.DataFrame({\"energy_star_rating\": y_pred}, index = X_test_submit_na.index)\n",
    "X_test_submit.fillna(value = y_pred_df, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "value = X_test_submit[\"direction_max_wind_speed\"]\n",
    "X_test_submit['dir_max_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                            np.where(value > 292.5, \"NE\",\n",
    "                                                    np.where(value > 247.5, \"E\",\n",
    "                                                             np.where(value > 202.5, \"SE\",\n",
    "                                                                      np.where(value > 157.5, \"S\",\n",
    "                                                                               np.where(value > 112.5, \"SW\",\n",
    "                                                                                        np.where(value > 67.5, \"W\",\n",
    "                                                                                                 np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "value = X_test_submit[\"direction_peak_wind_speed\"]\n",
    "X_test_submit['dir_peak_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                            np.where(value > 292.5, \"NE\",\n",
    "                                                    np.where(value > 247.5, \"E\",\n",
    "                                                             np.where(value > 202.5, \"SE\",\n",
    "                                                                      np.where(value > 157.5, \"S\",\n",
    "                                                                               np.where(value > 112.5, \"SW\",\n",
    "                                                                                        np.where(value > 67.5, \"W\",\n",
    "                                                                                                 np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "#value_floor = X_test_submit[\"floor_area\"]\n",
    "#X_test_submit['ord_floor_area'] =  np.where(value_floor > 261980, 7,\n",
    "#                              np.where(value_floor > 148466, 6,\n",
    "#                                     np.where(value_floor > 105070, 5,\n",
    "#                                            np.where(value_floor > 80088, 4,\n",
    "#                                                  np.where(value_floor > 65333, 3,\n",
    "#                                                         np.where(value_floor > 53250, 2, 1))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your submission model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model = pipe_xgb #stacking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.concat([X_train, X_test],ignore_index=True)\n",
    "y_final = pd.concat([y_train, y_test],ignore_index=True)\n",
    "pipe_fitted = select_model.fit(X_final, y_final);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': X_test_submit[\"id\"], 'site_eui': select_model.predict(X_test_submit)})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"add monthly temp diff with xgboost\"\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    path = \"../working/test.csv\"\n",
    "    submission.to_csv( path, index=False)\n",
    "else:\n",
    "    path = \"submission/test.csv\"\n",
    "    submission.to_csv(\"submission/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = !kaggle competitions submit -c widsdatathon2022  -f $path -m \"$message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show your latest score\n",
    "result = !kaggle competitions submissions -c widsdatathon2022 -v\n",
    "latest = pd.DataFrame(data=result)[0].str.split(',',expand=True).iloc[1:3,0:5]\n",
    "latest.columns = latest.iloc[0]\n",
    "latest = latest[1:]\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging (after submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = {}\n",
    "result = !kaggle competitions submissions -c widsdatathon2022 -v\n",
    "log['time'] = pd.DataFrame(data=result)[0].str.split(',',expand=True).loc[2,1]\n",
    "log['model'] = pipe_xgb\n",
    "log['columns'] = column_names\n",
    "log['score'] =pd.DataFrame(data=result)[0].str.split(',',expand=True).loc[2, 4]\n",
    "log['message'] = pd.DataFrame(data=result)[0].str.split(',',expand=True).loc[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'log.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(list(log.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:site_energy_consumption_prediction]",
   "language": "python",
   "name": "conda-env-site_energy_consumption_prediction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
