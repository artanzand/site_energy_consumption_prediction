{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define scoring metrics and CV score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metrics = {\n",
    "    \"neg RMSE\": \"neg_root_mean_squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "X_test_submit = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Any manual feature engineering before column transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Retail', 'Warehouse', 'Educational', 'Warehouse_cold', 'Office',\n",
       "       'Flex_space', 'Commercial', 'Industrial', 'Public_Assembly',\n",
       "       'Hotel', 'Health_care', 'Services', 'Food_services', 'Residential',\n",
       "       'Public_safety'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facility_class = pd.read_csv(\"f_type.csv\")\n",
    "facility_class[\"facility_class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Factor</th>\n",
       "      <th>State_Factor</th>\n",
       "      <th>building_class</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>floor_area</th>\n",
       "      <th>year_built</th>\n",
       "      <th>energy_star_rating</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>january_min_temp</th>\n",
       "      <th>january_avg_temp</th>\n",
       "      <th>...</th>\n",
       "      <th>days_above_90F</th>\n",
       "      <th>days_above_100F</th>\n",
       "      <th>days_above_110F</th>\n",
       "      <th>direction_max_wind_speed</th>\n",
       "      <th>direction_peak_wind_speed</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>days_with_fog</th>\n",
       "      <th>site_eui</th>\n",
       "      <th>id</th>\n",
       "      <th>facility_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>61242.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.682615</td>\n",
       "      <td>0</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>67346.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>287.863448</td>\n",
       "      <td>24</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>State_1</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Grocery_store_or_food_market</td>\n",
       "      <td>124196.0</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>36</td>\n",
       "      <td>50.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>241.932986</td>\n",
       "      <td>25</td>\n",
       "      <td>Retail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Factor State_Factor building_class                 facility_type  \\\n",
       "0            1      State_1     Commercial  Grocery_store_or_food_market   \n",
       "1            1      State_1     Commercial  Grocery_store_or_food_market   \n",
       "2            1      State_1     Commercial  Grocery_store_or_food_market   \n",
       "\n",
       "   floor_area  year_built  energy_star_rating  ELEVATION  january_min_temp  \\\n",
       "0     61242.0      1942.0                11.0        2.4                36   \n",
       "1     67346.0      1967.0                26.0        1.8                36   \n",
       "2    124196.0      1954.0                44.0        1.8                36   \n",
       "\n",
       "   january_avg_temp  ...  days_above_90F  days_above_100F  days_above_110F  \\\n",
       "0              50.5  ...               0                0                0   \n",
       "1              50.5  ...               0                0                0   \n",
       "2              50.5  ...               0                0                0   \n",
       "\n",
       "   direction_max_wind_speed  direction_peak_wind_speed  max_wind_speed  \\\n",
       "0                       1.0                        1.0             1.0   \n",
       "1                       1.0                        NaN             1.0   \n",
       "2                       1.0                        NaN             1.0   \n",
       "\n",
       "   days_with_fog    site_eui  id  facility_class  \n",
       "0            NaN  248.682615   0          Retail  \n",
       "1           12.0  287.863448  24          Retail  \n",
       "2           12.0  241.932986  25          Retail  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, facility_class, on=\"facility_type\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75757, 65)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = df[\"direction_max_wind_speed\"]\n",
    "df['dir_max_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                np.where(value > 292.5, \"NE\",\n",
    "                                        np.where(value > 247.5, \"E\",\n",
    "                                                 np.where(value > 202.5, \"SE\",\n",
    "                                                          np.where(value > 157.5, \"S\",\n",
    "                                                                   np.where(value > 112.5, \"SW\",\n",
    "                                                                            np.where(value > 67.5, \"W\",\n",
    "                                                                                     np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "value = df[\"direction_peak_wind_speed\"]\n",
    "df['dir_peak_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                np.where(value > 292.5, \"NE\",\n",
    "                                        np.where(value > 247.5, \"E\",\n",
    "                                                 np.where(value > 202.5, \"SE\",\n",
    "                                                          np.where(value > 157.5, \"S\",\n",
    "                                                                   np.where(value > 112.5, \"SW\",\n",
    "                                                                            np.where(value > 67.5, \"W\",\n",
    "                                                                                     np.where(value > 22.5, \"NW\", \"N\"))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75757, 67)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'E', 'NE'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dir_max_wind_speed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'NE', 'E'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dir_peak_wind_speed'].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "value_floor = df[\"floor_area\"]\n",
    "df['ord_floor_area'] =  np.where(value_floor > 261980, 7,\n",
    "                              np.where(value_floor > 148466, 6,\n",
    "                                     np.where(value_floor > 105070, 5,\n",
    "                                            np.where(value_floor > 80088, 4,\n",
    "                                                  np.where(value_floor > 65333, 3,\n",
    "                                                         np.where(value_floor > 53250, 2, 1))))))\n",
    "\n",
    "df.groupby(['ord_floor_area']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the data I realized that the mean wind direction is 62 degrees which aligns with NE that we are getting above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The following merges the imputed energy_star_rating\n",
    "# # This was done in R\n",
    "# df.to_csv(\"../data/train_facility.csv\") ## export for R MICE imputation\n",
    "# energy_star_imp = pd.read_csv(\"energy_star_imp.csv\")\n",
    "# df = pd.merge(df, energy_star_imp, on=\"facility_class\")\n",
    "# df['energy_star_rating'] = df['energy_star_rating'].fillna(df.pop('energy_star_rating_imp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        11.0\n",
       "1        26.0\n",
       "2        44.0\n",
       "3        55.0\n",
       "4        23.0\n",
       "         ... \n",
       "75752    38.0\n",
       "75753    69.0\n",
       "75754    96.0\n",
       "75755    73.0\n",
       "75756    69.0\n",
       "Name: energy_star_rating, Length: 49048, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute train set using KNN\n",
    "to_train = df[~df[\"energy_star_rating\"].isna()]\n",
    "to_impute = df[df[\"energy_star_rating\"].isna()]\n",
    "\n",
    "X_train_KNN = to_train[[\"floor_area\", \"facility_class\", \"year_built\"]]\n",
    "y_train_KNN = to_train[\"energy_star_rating\"]\n",
    "\n",
    "X_test_KNN = to_impute[[\"floor_area\", \"facility_class\", \"year_built\"]]\n",
    "\n",
    "y_train_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = [\"floor_area\", \"year_built\"]\n",
    "categorical = [\"facility_class\"]\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=True),\n",
    ")\n",
    "\n",
    "KNN_preprocessor = make_column_transformer(\n",
    "    (numeric, StandardScaler()),\n",
    "    (categorical, categorical_transformer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_pipe = make_pipeline(\n",
    "    KNN_preprocessor, KNeighborsRegressor(n_neighbors=5, n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 671, in fit_transform\n",
      "    self._validate_transformers()\n",
      "  File \"C:\\Users\\artan\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 336, in _validate_transformers\n",
      "    raise TypeError(\n",
      "TypeError: All estimators should implement fit and transform, or can be 'drop' or 'passthrough' specifiers. '['floor_area', 'year_built']' (type <class 'list'>) doesn't.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg RMSE</th>\n",
       "      <th>train_neg RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN_imputer</th>\n",
       "      <td>0.003 (+/- 0.001)</td>\n",
       "      <td>0.000 (+/- 0.000)</td>\n",
       "      <td>nan (+/- nan)</td>\n",
       "      <td>nan (+/- nan)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fit_time         score_time  test_neg RMSE  \\\n",
       "KNN_imputer  0.003 (+/- 0.001)  0.000 (+/- 0.000)  nan (+/- nan)   \n",
       "\n",
       "            train_neg RMSE  \n",
       "KNN_imputer  nan (+/- nan)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results[\"KNN_imputer\"] = mean_std_cross_val_scores(\n",
    "    KNN_pipe, X_train_KNN, y_train_KNN, return_train_score=True, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All estimators should implement fit and transform, or can be 'drop' or 'passthrough' specifiers. '['floor_area', 'year_built']' (type <class 'list'>) doesn't.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4260/2726401266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit-predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mKNN_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_KNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_KNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mto_impute\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"energy_star_rating\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNN_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_KNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \"\"\"\n\u001b[0;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;31m# set n_features_in_ attribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\site_energy_consumption_prediction\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_validate_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transform\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             ):\n\u001b[1;32m--> 336\u001b[1;33m                 raise TypeError(\n\u001b[0m\u001b[0;32m    337\u001b[0m                     \u001b[1;34m\"All estimators should implement fit and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m                     \u001b[1;34m\"transform, or can be 'drop' or 'passthrough' \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: All estimators should implement fit and transform, or can be 'drop' or 'passthrough' specifiers. '['floor_area', 'year_built']' (type <class 'list'>) doesn't."
     ]
    }
   ],
   "source": [
    "# Fit-predict\n",
    "KNN_pipe.fit(X_train_KNN, y_train_KNN)\n",
    "to_impute[\"energy_star_rating\"] = KNN_pipe.predict(X_test_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the two df's together\n",
    "X_train = pd.concat([to_train, to_impute], axis=0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group columns for transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"site_eui\"\n",
    "\n",
    "numeric_features = [\n",
    "    \"floor_area\", # Grouped and moved to ordinary feature\n",
    "    \"year_built\",\n",
    "    \"energy_star_rating\", # Imputed by facility_class + site_eui, take the average per facility_class\n",
    "    # \"ELEVATION\", \n",
    "    \"january_min_temp\",\n",
    "    \"january_avg_temp\",\n",
    "    \"january_max_temp\",\n",
    "#    \"february_min_temp\", # removed similar temperature columns\n",
    "#    \"february_avg_temp\",\n",
    "#    \"february_max_temp\",\n",
    "#    \"march_min_temp\",\n",
    "#    \"march_avg_temp\",\n",
    "#    \"march_max_temp\",\n",
    "#    \"april_min_temp\",\n",
    "#    \"april_avg_temp\",\n",
    "#    \"april_max_temp\",\n",
    "#    \"may_min_temp\",\n",
    "#    \"may_avg_temp\",\n",
    "#    \"may_max_temp\",\n",
    "#    \"june_min_temp\",\n",
    "#    \"june_avg_temp\",\n",
    "#    \"june_max_temp\",\n",
    "    \"july_min_temp\",\n",
    "    \"july_avg_temp\",\n",
    "    \"july_max_temp\",\n",
    "    \"august_min_temp\",\n",
    "    \"august_avg_temp\",\n",
    "    \"august_max_temp\",\n",
    "#    \"september_min_temp\", # removed similar temperature columns\n",
    "#    \"september_avg_temp\",\n",
    "#    \"september_max_temp\",\n",
    "#    \"october_min_temp\",\n",
    "#    \"october_avg_temp\",\n",
    "#    \"october_max_temp\",\n",
    "#    \"november_min_temp\",\n",
    "#    \"november_avg_temp\",\n",
    "#    \"november_max_temp\",\n",
    "#    \"december_min_temp\",\n",
    "#    \"december_avg_temp\",\n",
    "#    \"december_max_temp\",\n",
    "    \"cooling_degree_days\",\n",
    "    \"heating_degree_days\",\n",
    "    \"precipitation_inches\",\n",
    "    \"snowfall_inches\",\n",
    "    \"snowdepth_inches\",\n",
    "    \"avg_temp\",\n",
    "#    \"days_below_30F\",\n",
    "    \"days_below_20F\",\n",
    "#    \"days_below_10F\", \n",
    "#    \"days_below_0F\",\n",
    "#    \"days_above_80F\",\n",
    "    \"days_above_90F\",\n",
    "#    \"days_above_100F\",\n",
    "#    \"days_above_110F\",\n",
    "#    \"direction_max_wind_speed\",\n",
    "#    \"direction_peak_wind_speed\",\n",
    "    \"max_wind_speed\",\n",
    "    \"days_with_fog\" ##???\n",
    "]\n",
    "\n",
    "ordinal_features = [] #['ord_floor_area']\n",
    "categorical_features = [\n",
    "                        \"Year_Factor\",  # Moved this down from numeric \n",
    "                        \"State_Factor\",\n",
    "                        \"facility_class\",\n",
    "                        \"facility_type\",\n",
    "                        \"dir_max_wind_speed\",  # Added new feature\n",
    "                        \"dir_peak_wind_speed\"]  # Added\n",
    "\n",
    "drop_features = [\n",
    "    \"id\",\n",
    "    \"building_class\", # Moved this one here \n",
    "    #\"floor_area\", # Grouped and moved this one here \n",
    "    \"direction_max_wind_speed\",\n",
    "    \"direction_peak_wind_speed\",\n",
    "    \"february_min_temp\",\n",
    "    \"february_avg_temp\",\n",
    "    \"february_max_temp\",\n",
    "    \"march_min_temp\",\n",
    "    \"march_avg_temp\",\n",
    "    \"march_max_temp\",\n",
    "    \"april_min_temp\",\n",
    "    \"april_avg_temp\",\n",
    "    \"april_max_temp\",\n",
    "    \"may_min_temp\",\n",
    "    \"may_avg_temp\",\n",
    "    \"may_max_temp\",\n",
    "    \"june_min_temp\",\n",
    "    \"june_avg_temp\",\n",
    "    \"june_max_temp\",    \n",
    "    \"september_min_temp\",\n",
    "    \"september_avg_temp\",\n",
    "    \"september_max_temp\",    \n",
    "    \"october_min_temp\",\n",
    "    \"october_avg_temp\",\n",
    "    \"october_max_temp\",\n",
    "    \"november_min_temp\",\n",
    "    \"november_avg_temp\",\n",
    "    \"november_max_temp\",\n",
    "    \"december_min_temp\",\n",
    "    \"december_avg_temp\",\n",
    "    \"december_max_temp\",    \n",
    "    \"days_below_30F\",    \n",
    "    \"days_below_10F\",\n",
    "    \"days_below_0F\",\n",
    "    \"days_above_80F\",    \n",
    "    \"days_above_100F\",\n",
    "    \"days_above_110F\",    \n",
    "    \"ELEVATION\", #Try dropping\n",
    "]\n",
    "\n",
    "assert df.columns.shape[0] == len(\n",
    "    numeric_features\n",
    "    + ordinal_features\n",
    "    + categorical_features\n",
    "    + [target]\n",
    "    + drop_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=123)\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_test, y_test = test_df.drop(columns=[target]), test_df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column transformation & preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=0), StandardScaler())\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check transformed df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = (\n",
    "    numeric_features\n",
    "    + preprocessor.named_transformers_[\"pipeline-2\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "X_train_transformed_df = pd.DataFrame(\n",
    "    X_train_transformed.toarray(), columns=column_names, index=X_train.index\n",
    ")\n",
    "\n",
    "X_train_transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy regressor as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "pipe_dummy = DummyRegressor()\n",
    "results[\"Dummy\"] = mean_std_cross_val_scores(\n",
    "    pipe_dummy, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train several models (CV) and retrieve the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ridge = make_pipeline(preprocessor, Ridge(random_state=123))\n",
    "\n",
    "pipe_rf = make_pipeline(\n",
    "    preprocessor, RandomForestRegressor(random_state=123, n_jobs=-1, max_depth=5)\n",
    ")\n",
    "\n",
    "pipe_xgb = make_pipeline(\n",
    "    preprocessor, XGBRegressor(random_state=123, n_jobs=-1, verbosity=0)\n",
    ")\n",
    "\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMRegressor(random_state=123))\n",
    "\n",
    "pipe_catboost = make_pipeline(\n",
    "    preprocessor, CatBoostRegressor(random_state=123, verbose=0)\n",
    ")\n",
    "\n",
    "models = {\n",
    "    #\"Ridge\": pipe_ridge, ## high mse\n",
    "    #\"Random Forest\": pipe_rf,\n",
    "    \"XGBoost\": pipe_xgb,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost,\n",
    "    #\"kNN\": pipe_kNN,  ## high mse\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    results[model_name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid_xgb = {\n",
    "     \"xgbregressor__max_depth\": np.linspace(start=1, stop=20, num=5, dtype=int),\n",
    "     \"xgbregressor__min_child_weight\": np.linspace(start=1, stop=20, num=5, dtype=int),\n",
    "     \"xgbregressor__subsample\": np.logspace(-3, 0, 10),\n",
    "     \"xgbregressor__colsample_bytree\": np.logspace(-3, 0, 10),\n",
    "     \"xgbregressor__eta\": np.logspace(-3, 0, 10)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xgb_search_rf = RandomizedSearchCV(\n",
    "    pipe_xgb,\n",
    "    param_grid_xgb,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    random_state=123,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "xgb_search_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train =  h2o.H2OFrame(df)\n",
    "aml = H2OAutoML(max_runtime_secs=2000, seed=1)\n",
    "aml.train(x=numeric_features + ordinal_features + categorical_features, y=target, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model = VotingRegressor(\n",
    "    list(models.items())\n",
    ")  # need the list() here for cross-validation to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Voting\"] = mean_std_cross_val_scores(\n",
    "    averaging_model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model = StackingRegressor(\n",
    "    list(models.items())\n",
    ")  # need the list() here for cross-validation to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Stacking\"] = mean_std_cross_val_scores(\n",
    "    stacking_model, X_train, y_train, return_train_score=True, scoring=scoring_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = averaging_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_fitted = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = pipe.score(X_test, y_test)\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of test set\n",
    "X_test_submit = pd.merge(X_test_submit, facility_class, on=\"facility_type\")\n",
    "\n",
    "# Impute energy_star_rating\n",
    "# X_test_submit = pd.merge(X_test_submit, energy_star_imp, on=\"facility_class\")\n",
    "# X_test_submit['energy_star_rating'] = X_test_submit['energy_star_rating'].fillna(X_test_submit.pop('energy_star_rating_imp'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "value = X_test_submit[\"direction_max_wind_speed\"]\n",
    "X_test_submit['dir_max_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                            np.where(value > 292.5, \"NE\",\n",
    "                                                    np.where(value > 247.5, \"E\",\n",
    "                                                             np.where(value > 202.5, \"SE\",\n",
    "                                                                      np.where(value > 157.5, \"S\",\n",
    "                                                                               np.where(value > 112.5, \"SW\",\n",
    "                                                                                        np.where(value > 67.5, \"W\",\n",
    "                                                                                                 np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "value = X_test_submit[\"direction_peak_wind_speed\"]\n",
    "X_test_submit['dir_peak_wind_speed'] = np.where(value > 337.5, \"N\",\n",
    "                                            np.where(value > 292.5, \"NE\",\n",
    "                                                    np.where(value > 247.5, \"E\",\n",
    "                                                             np.where(value > 202.5, \"SE\",\n",
    "                                                                      np.where(value > 157.5, \"S\",\n",
    "                                                                               np.where(value > 112.5, \"SW\",\n",
    "                                                                                        np.where(value > 67.5, \"W\",\n",
    "                                                                                                 np.where(value > 22.5, \"NW\", \"N\"))))))))\n",
    "\n",
    "#value_floor = X_test_submit[\"floor_area\"]\n",
    "#X_test_submit['ord_floor_area'] =  np.where(value_floor > 261980, 7,\n",
    "#                              np.where(value_floor > 148466, 6,\n",
    "#                                     np.where(value_floor > 105070, 5,\n",
    "#                                            np.where(value_floor > 80088, 4,\n",
    "#                                                  np.where(value_floor > 65333, 3,\n",
    "#                                                         np.where(value_floor > 53250, 2, 1))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select your submission model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model = pipe_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.concat([X_train, X_test],ignore_index=True)\n",
    "y_final = pd.concat([y_train, y_test],ignore_index=True)\n",
    "pipe_fitted = select_model.fit(X_final, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': X_test_submit[\"id\"], 'site_eui': select_model.predict(X_test_submit)})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test =  h2o.H2OFrame(X_test_submit)\n",
    "preds = aml.predict(test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "submission2 = pd.DataFrame({'id': X_test_submit[\"id\"], 'site_eui': h2o.as_list(preds)['predict']})\n",
    "submission2.head()\n",
    "submission2.to_csv(\"test3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:site_energy_consumption_prediction]",
   "language": "python",
   "name": "conda-env-site_energy_consumption_prediction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
